# ğŸµ Audio Deepfake Detection System

A state-of-the-art deep learning system to detect synthetic audio, voice conversion, and deepfakes using advanced 2D CNN architectures with multiple ensemble strategies.

## ğŸ¯ Overview

This system analyzes audio files to distinguish between:
- **REAL** (Bona fide): Genuine human speech
- **FAKE** (Deepfake/Synthetic): AI-generated or voice-converted speech

It uses multi-feature audio processing (Mel-Spectrograms, MFCC, Phase) combined with ensemble learning for maximum accuracy.

---

## âœ¨ Key Features

### ğŸ¨ Multiple Model Architectures
- **Enhanced CNN**: Full-featured model using all 3 audio features
- **Lightweight CNN**: Fast real-time model for edge deployment
- **Ensemble Methods**:
  - Standard (Weighted averaging)
  - MultiScale (Multi-resolution processing)
  - Adaptive (Input-aware fusion)

### ğŸ–¼ï¸ Advanced Audio Features
- **Mel-Spectrograms**: Multi-scale spectral analysis
- **MFCC**: Cepstral coefficients with delta features
- **Phase Features**: Instantaneous frequency analysis

### ğŸš€ Dual Interface
- **Streamlit Web App** (`app.py`): Interactive UI with visualizations
- **FastAPI REST API** (`main.py`): Production-ready backend

### ğŸ“ Comprehensive Dataset
- Trained on ASVspoof 2019 dataset
- Handles various synthetic speech and voice conversion techniques

---

## ğŸš€ Quick Start

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2: Initialize Models
```bash
python init_models.py
```

### Step 3: Launch Streamlit App
```bash
streamlit run app.py
```

Visit `http://localhost:8501` to use the app!

---

## ğŸ“– Full Setup Guide

For detailed installation and configuration instructions, see [SETUP.md](SETUP.md)

---

## ğŸ“Š Model Comparison

| Model | Features | Speed | Accuracy | Best For |
|-------|----------|-------|----------|----------|
| Enhanced | 3 | Medium | High | General use |
| Lightweight | 1 | Very Fast | Medium | Real-time |
| Standard Ensemble | 3+ | Slow | Very High | High accuracy |
| MultiScale Ensemble | 3+ | Slowest | Very High | Complex patterns |
| Adaptive Ensemble | 3+ | Slow | Very High | Variable quality |

---

## ğŸ–¥ï¸ Streamlit App

### Features
- **Upload Audio**: WAV or MP3 files
- **Real-time Analysis**: Waveform and spectrogram visualization
- **Model Selection**: Switch between different models
- **Confidence Scores**: Probability of prediction
- **Technical Explanations**: Understanding the model's reasoning

### Select Models in Sidebar
1. **Enhanced**: High accuracy with all features
2. **Lightweight**: Fast inference
3. **Ensemble**: Best performance with three strategies

---

## ğŸ”Œ FastAPI REST API

### Quick Test
```bash
python main.py
```

### Endpoints

#### Get Information
```bash
curl http://localhost:8000/
```

#### List Available Models
```bash
curl http://localhost:8000/models
```

#### Make Prediction
```bash
curl -X POST http://localhost:8000/predict \
  -F "file=@audio.wav" \
  "?model_type=ensemble&ensemble_type=adaptive"
```

Response:
```json
{
  "filename": "audio.wav",
  "prediction": "REAL",
  "confidence": 0.95,
  "model_type": "ensemble",
  "ensemble_type": "adaptive",
  "status": "success"
}
```

---

## ğŸ“ Project Structure

```
audio-deepfake-detection/
â”œâ”€â”€ ğŸµ app.py                     # Streamlit web application
â”œâ”€â”€ ğŸ”Œ main.py                    # FastAPI server
â”œâ”€â”€ ğŸ”§ init_models.py             # Model initialization script
â”‚
â”œâ”€â”€ ğŸ“š src/
â”‚   â”œâ”€â”€ model.py                  # CNN architectures
â”‚   â”œâ”€â”€ ensemble.py               # Ensemble models
â”‚   â”œâ”€â”€ train.py                  # Training pipeline
â”‚   â”œâ”€â”€ eval.py                   # Evaluation metrics
â”‚   â”œâ”€â”€ augmentation.py           # Data augmentation
â”‚   â”œâ”€â”€ optimization.py           # Model optimization
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ ğŸ’¾ model/
â”‚   â”œâ”€â”€ enhanced_model.pth        # Enhanced model (15.09 MB)
â”‚   â”œâ”€â”€ lightweight_model.pth     # Lightweight model (0.40 MB)
â”‚   â””â”€â”€ ensemble_*.pth            # Ensemble models
â”‚
â”œâ”€â”€ âš™ï¸ .streamlit/
â”‚   â””â”€â”€ config.toml               # Streamlit settings
â”‚
â”œâ”€â”€ ğŸ“‹ config.yaml                # System configuration
â”œâ”€â”€ ğŸ“– README.md                  # This file
â”œâ”€â”€ ğŸ“– SETUP.md                   # Detailed setup guide
â”œâ”€â”€ ğŸ“¦ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ”§ setup.py                   # Setup script
â”œâ”€â”€ ğŸ› ï¸ utils.py                   # Utility functions
â””â”€â”€ .venv/                        # Virtual environment
```

---

## ğŸ”§ Requirements

- **Python**: 3.8+
- **CUDA**: Optional (for GPU acceleration)
- **RAM**: 8GB minimum
- **Storage**: 500MB+

See `requirements.txt` for full list of dependencies.

---

## ğŸ“š Architecture Details

### Enhanced CNN
- **Input**: 3 feature types (128Ã—128 spectrograms)
- **Processing**: Residual blocks with self-attention
- **Output**: Binary classification (Real/Fake)

### Ensemble Methods
1. **Standard**: Weighted averaging of model outputs
2. **MultiScale**: Multi-resolution temporal processing
3. **Adaptive**: Dynamic weighting based on input characteristics

See [src/model.py](src/model.py) and [src/ensemble.py](src/ensemble.py) for implementation details.

---

## ğŸ“ Training Custom Models

To train with your own data:

```bash
python src/train.py
```

Configuration in `config.yaml`:
- Model hyperparameters
- Data augmentation settings
- Training schedule
- Audio processing parameters

See [SETUP.md](SETUP.md) for detailed training guide.

---

## ğŸ“Š Performance Metrics

The system evaluates models using:
- **Accuracy**: Percentage of correct predictions
- **Precision/Recall**: Per-class performance
- **ROC-AUC**: Discrimination ability
- **EER**: Equal Error Rate (anti-spoofing metric)

Evaluation tools in [src/eval.py](src/eval.py)

---

## ğŸ› Troubleshooting

### Models not found
```bash
python init_models.py
```

### Import errors
```bash
pip install -r requirements.txt --upgrade
```

See [SETUP.md](SETUP.md) for more troubleshooting tips.

---

## ğŸ“ Dataset

- **ASVspoof 2019 LA Database**
- 51,000+ speech samples
- Multiple synthetic speech types
- Voice conversion techniques
- Real and spoofed utterances

Learn more: https://www.asvspoof.org/

---

## ğŸ” Audio Features Explained

### Mel-Spectrogram
Frequency domain representation using mel-scale (human hearing perception). Better for detecting subtle audio artifacts.

### MFCC (Mel-Frequency Cepstral Coefficients)
Captures phonetic information. Includes first and second derivatives for temporal dynamics.

### Phase Features
Instantaneous frequency analysis. Useful for detecting unnatural phase coherence in synthetic speech.

---

## ğŸ’¡ How It Works

1. **Audio Input**: User uploads WAV or MP3 file
2. **Feature Extraction**: Convert to 3 audio feature types
3. **Model Processing**: Run through selected model/ensemble
4. **Classification**: Output probability for Real/Fake
5. **Visualization**: Display waveform, spectrogram, and results

---

## ğŸš€ Deployment

### Streamlit Cloud
```bash
streamlit run app.py
```

### Docker (Coming Soon)
```bash
docker build -t audio-deepfake .
docker run -p 8501:8501 audio-deepfake
```

### Kubernetes
Configuration files available for production deployment.

---

## ğŸ“„ License

[Specify your license here]

---

## ğŸ‘¥ Authors

[Your name/organization]

---

## ğŸ™ Acknowledgments

- ASVspoof Challenge organizers
- PyTorch community
- Librosa audio processing library

---

## ğŸ“ Support

For issues, questions, or contributions:
1. Check [SETUP.md](SETUP.md) for common issues
2. Review [src/](src/) for technical details
3. Open an issue on GitHub

---

## â­ Quick Links

- ğŸ“– [Setup Guide](SETUP.md)
- ğŸ¯ [Configuration](config.yaml)
- ğŸ“š [Model Details](src/model.py)
- ğŸ”¬ [Training Guide](src/train.py)
- ğŸ“Š [Evaluation](src/eval.py)

---

**Ready to detect deepfakes? Start with:**
```bash
streamlit run app.py
```

Happy ğŸµ analyzing!
